{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "As methods such as 'Decision Tree' can be prone to the error of 'overfitting' on the training set which can in return lead to wrong predictions on new data, BOOTSTARP AGGREGATION (Bagging) is an ensembling style which attempts to resolve the overfitting error for regression or classification problems.\n",
    "\n",
    "Bagging's objective is to improve the accuracy and performance of ml algorithms by randomly taking subsets of the original datasets, with replacement, then fitting either a regressor(for regression) or a classifier(for classification) to each subset.\n",
    "predictions for each of these subsets are then aggregated via majority voting for classification, or averaginf for regression, thereby increasing the prediction's accuracy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluatng the Base Classifier: \n",
    "\n",
    "# import neccesary modules\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# load datasets\n",
    "data = datasets.load_wine(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# split X and y into train/test to properly evaluate our model on unseen data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=22)\n",
    "\n",
    "# instantiate Base Classifier and fit it to training data\n",
    "dt = DecisionTreeClassifier(random_state=22)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# predict the class of wine the unseen test set and evaluate the model performance\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Train data accuracy: \", accuracy_score(y_true = y_train, y_pred = dt.predict(X_train)))\n",
    "print(\"Test data accuracy: \", accuracy_score(y_true = y_test, y_pred = y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "data = datasets.load_wine(as_frame = True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 22)\n",
    "\n",
    "estimator_range = [2,4,6,8,10,12,14,16]\n",
    "\n",
    "models = []\n",
    "scores = []\n",
    "\n",
    "for n_estimators in estimator_range:\n",
    "\n",
    "    # Create bagging classifier\n",
    "    clf = BaggingClassifier(n_estimators = n_estimators, random_state = 22)\n",
    "\n",
    "    # Fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Append the model and score to their respective list\n",
    "    models.append(clf)\n",
    "    scores.append(accuracy_score(y_true = y_test, y_pred = clf.predict(X_test)))\n",
    "\n",
    "# Generate the plot of scores against number of estimators\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(estimator_range, scores)\n",
    "\n",
    "# Adjust labels and font (to make visable)\n",
    "plt.xlabel(\"n_estimators\", fontsize = 18)\n",
    "plt.ylabel(\"score\", fontsize = 18)\n",
    "plt.tick_params(labelsize = 16)\n",
    "\n",
    "# Visualize plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By iterating through different values for the number of estimators we can see an increase in model performance from 82.2% to 95.5%. After 14 estimators the accuracy begins to drop, again if you set a different random_state the values you see will vary. That is why it is best practice to use cross validation to ensure stable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Another Form of Evaluation\n",
    "As bootstrapping chooses random subsets of observations to create classifiers, there are observations that are left out in the selection process. These \"out-of-bag\" observations can then be used to evaluate the model, similarly to that of a test set. Keep in mind, that out-of-bag estimation can overestimate error in binary classification problems and should only be used as a compliment to other metrics.\n",
    "\n",
    "We saw in the last exercise that 12 estimators yielded the highest accuracy, so we will use that to create our model. This time setting the parameter oob_score to true to evaluate the model with out-of-bag score.\n",
    "\"\"\"\n",
    "\n",
    "# creating a model with out-of-bag metric\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "data = datasets.load_wine(as_frame=True)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=22)\n",
    "oob_model = BaggingClassifier(n_estimators=12, oob_score=True, random_state=22)\n",
    "oob_model.fit(X_train, y_train)\n",
    "\n",
    "print(oob_model.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the samples used in OOB and the test set are different, and the dataset is relatively small, there is a difference in the accuracy. It is rare that they would be exactly the same, again OOB should be used quick means for estimating error, but is not the only evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating decision tree from bagging classifier\n",
    "\n",
    "\"\"\"\n",
    "It is also possible to see the individual decision trees that went into the aggregated classifier. This helps us to gain a more intuitive understanding on how the bagging model arrives at its predictions.\n",
    "\n",
    "Note: This is only functional with smaller datasets, where the trees are relatively shallow and narrow making them easy to visualize.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=22)\n",
    "clf = BaggingClassifier(n_estimators=12, oob_score=True, random_state=22)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "plt.figure(figsize=(30, 20))\n",
    "plot_tree(clf.estimators_[0], feature_names=X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
